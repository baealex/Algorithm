{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(9, dtype=tf.float32, name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 81.0\n",
      "2) 4.5\n",
      "3) 3.0\n"
     ]
    }
   ],
   "source": [
    "y = tf.square(x) # 제곱\n",
    "print('1) ' + str(session.run(y)))  # 81.0, session.run(그래프명)\n",
    "\n",
    "y = tf.reduce_mean([4.0, 5.0])   # 평균\n",
    "print('2) ' + str(session.run(y)))  # 4.5\n",
    "\n",
    "y = tf.sqrt(x)  # √ 9의 제곱근\n",
    "print('3) ' + str(session.run(y)))  # 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n",
      "[81, 93, 91, 97]\n"
     ]
    }
   ],
   "source": [
    "# x, y의 데이터 값\n",
    "# ----------------------------------\n",
    "# 공부 시간: 2   4   6   8\n",
    "# 시험 성적: 81  93  91  97\n",
    "# ----------------------------------\n",
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x_data = [x_row[0] for x_row in data]\n",
    "print(x_data)\n",
    "\n",
    "y_data = [y_row[1] for y_row in data]\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'atest:0' shape=(1,) dtype=float64_ref>\n",
      "[8.06901302]\n",
      "<tf.Variable 'btest:0' shape=(1,) dtype=float64_ref>\n",
      "[80.69013021]\n"
     ]
    }
   ],
   "source": [
    "# 균등분포 난수 발생: tf.random_uniform(shape, 최소값, 최대값)\n",
    "atest = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0), name='atest')\n",
    "btest = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0), name='btest')\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "print(atest)\n",
    "print(session.run(atest))\n",
    "print(btest)\n",
    "print(session.run(btest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 최적값을 모름으로 균등 분포 지원 난수 생성\n",
    "# tf.random_uniform(shape, 최소값, 최대값)\n",
    "a = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0), name='a')\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0), name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# 발생한 정규분포 값을 가지고 y에 대한 일차 방정식 ax + b를 이용하여 List 형식의 y를 산출, 갯수 4개\n",
    "# x_data: [2, 4, 6, 8]\n",
    "y = a * x_data + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sqrt_1:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# reduce_mean: 텐서플로 RMSE(Root Mean Squared Error) 평균 제곱근 오차 함수\n",
    "# 평균 오차를 줄이는 역활을 함.\n",
    "# 오차 = y(예측 성적, List 형식) - y_data(실제 성적)\n",
    "# square: 제곱, reduce_mean: 모든 차원을 줄이고 하나의 스칼라값인 평균을 출력, sqrt: 루트\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square((y) - y_data)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> gradient_decent type:  <class 'tensorflow.python.framework.ops.Operation'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률을 0.1로 가정\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE 값을 최소로 하는 값 찾기, 경사 하강법 자동 실행, 학습률과 평균 제곱근 오차 함수 선언\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "# <class 'tensorflow.python.framework.ops.Operation'>\n",
    "print('--> gradient_decent type: ', type(gradient_decent))\n",
    "gradient_decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) a(기울기 가정):  [8.06901302]\n",
      "2) b(y 절편 가정):  [80.69013021]\n",
      "3) 성적 산출 예상 공식(1차 함수 그래프): y = 8.0690x + 80.6901\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "# 변수 초기화\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# 텐서플로를 이용한 학습\n",
    "print('1) a(기울기 가정): ', session.run(a))\n",
    "print('2) b(y 절편 가정): ', session.run(b))\n",
    "print('3) 성적 산출 예상 공식(1차 함수 그래프): y = %.4fx + %.4f' % (session.run(a), session.run(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4) 예상 성적 y List 값:  [ 96.82815626 112.9661823  129.10420834 145.24223438]\n",
      "5) rmse(평균 제곱근 오차):  33.27319806435078\n",
      "6) learning_rate(학습률):  0.1\n"
     ]
    }
   ],
   "source": [
    "print('4) 예상 성적 y List 값: ', session.run(y))\n",
    "print('5) rmse(평균 제곱근 오차): ', session.run(rmse))\n",
    "print('6) learning_rate(학습률): ', learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7) Tensorflow에의한 경사 하강법을 이용한 기울기a와 y절편 b 최적화 시작\n",
      "Epoch: 0, RMSE = 30.2139, 기울기 a = 7.5235, y 절편 b = 80.5984\n",
      "Epoch: 200, RMSE = 2.8826, 기울기 a = 2.2601, y 절편 b = 79.2379\n",
      "Epoch: 400, RMSE = 2.8811, 기울기 a = 2.2871, y 절편 b = 79.0770\n",
      "Epoch: 600, RMSE = 2.8810, 기울기 a = 2.2958, y 절편 b = 79.0249\n",
      "Epoch: 800, RMSE = 2.8810, 기울기 a = 2.2987, y 절편 b = 79.0081\n",
      "Epoch: 1000, RMSE = 2.8810, 기울기 a = 2.2996, y 절편 b = 79.0026\n",
      "Epoch: 1200, RMSE = 2.8810, 기울기 a = 2.2999, y 절편 b = 79.0008\n",
      "Epoch: 1400, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0003\n",
      "Epoch: 1600, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0001\n",
      "Epoch: 1800, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0000\n",
      "Epoch: 2000, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0000\n",
      "08) 최적의 산출 공식: y = 2.3x + 79\n"
     ]
    }
   ],
   "source": [
    "print('7) Tensorflow에의한 경사 하강법을 이용한 기울기a와 y절편 b 최적화 시작')\n",
    "# 2001번 실행(0번 째를 포함하므로)\n",
    "for step in range(2001): # 0 ~ 2000\n",
    "    session.run(gradient_decent)\n",
    "    if step % 200 == 0:  # 200번마다 결과 출력\n",
    "        v_rmse = session.run(rmse)  # 평균 제곱근 오차, y - y_data → (a * x_data + b) - ydata\n",
    "        v_a = session.run(a)        # 기울기, 난수로 생성\n",
    "        v_b = session.run(b)        # Y 절편, 난수로 생성\n",
    "        # Epoch: 반복 횟수\n",
    "        print(\"Epoch: %.f, RMSE = %.04f, 기울기 a = %.4f, y 절편 b = %.4f\" % (step, v_rmse, v_a, v_b))\n",
    "\n",
    "print('08) 최적의 산출 공식: y = %.1fx + %.d' % (v_a, v_b))  # y = 2.3x + 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09) 산출된 최적의 방정식: y = 2.3x + 79\n",
      "공부 시간: 2 예상 성적: 83 \n",
      "공부 시간: 4 예상 성적: 88 \n",
      "공부 시간: 6 예상 성적: 92 \n",
      "공부 시간: 8 예상 성적: 97 \n"
     ]
    }
   ],
   "source": [
    "# 테스트, 검증\n",
    "print('09) 산출된 최적의 방정식: y = 2.3x + 79')\n",
    "\n",
    "# 공부 시간: 2   4   6   8\n",
    "# 시험 성적: 81  93  91  97\n",
    "test_data=[2, 4, 6, 8]\n",
    "for i in range(len(test_data)):\n",
    "    y = 2.3 * test_data[i] + 79  # y = ax + b, y = 2.3x + 79 가정\n",
    "    print('공부 시간: %d 예상 성적: %d ' % (test_data[i], y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 31.5903, 기울기 a = 7.7690, y 절편 b = 80.6397\n",
      "Epoch: 200, RMSE = 2.8855, 기울기 a = 2.2336, y 절편 b = 79.3961\n",
      "Epoch: 400, RMSE = 2.8823, 기울기 a = 2.2643, y 절편 b = 79.2132\n",
      "Epoch: 600, RMSE = 2.8814, 기울기 a = 2.2808, y 절편 b = 79.1147\n",
      "Epoch: 800, RMSE = 2.8811, 기울기 a = 2.2897, y 절편 b = 79.0617\n",
      "Epoch: 1000, RMSE = 2.8810, 기울기 a = 2.2944, y 절편 b = 79.0332\n",
      "Epoch: 1200, RMSE = 2.8810, 기울기 a = 2.2970, y 절편 b = 79.0179\n",
      "Epoch: 1400, RMSE = 2.8810, 기울기 a = 2.2984, y 절편 b = 79.0096\n",
      "Epoch: 1600, RMSE = 2.8810, 기울기 a = 2.2991, y 절편 b = 79.0052\n",
      "Epoch: 1800, RMSE = 2.8810, 기울기 a = 2.2995, y 절편 b = 79.0028\n",
      "Epoch: 2000, RMSE = 2.8810, 기울기 a = 2.2997, y 절편 b = 79.0015\n",
      "10) 학습률 0.055: y = 2.3x + 79 2시간 예상 성적: 83\n"
     ]
    }
   ],
   "source": [
    "# 학습률을 변경하여 테스트, 적당하지 않은 학습률은 최소 오차를 넘어가 경사면의 기울기를 크게한다.\n",
    "lean_a = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "bias_b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
    "y = lean_a * x_data + bias_b\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square((y) - y_data)))\n",
    "learning_rate = 0.055\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# 2001번 실행(0번 째를 포함하므로)\n",
    "for step in range(2001): # 0 ~ 2000\n",
    "    session.run(gradient_decent)\n",
    "    if step % 200 == 0:  # 200번마다 결과 출력\n",
    "        v_rmse = session.run(rmse)  # 평균 제곱근 오차, y - y_data → (a * x_data + b) - ydata\n",
    "        v_lean_a = session.run(lean_a)        # 기울기, 난수로 생성\n",
    "        v_bias_b = session.run(bias_b)        # Y 절편, 난수로 생성\n",
    "        # Epoch: 반복 횟수\n",
    "        print(\"Epoch: %.f, RMSE = %.04f, 기울기 a = %.4f, y 절편 b = %.4f\" % (step, v_rmse, v_lean_a, v_bias_b))\n",
    "\n",
    "print('10) 학습률 %.3f: y = %.1fx + %.f 2시간 예상 성적: %d' % (learning_rate, v_lean_a, v_bias_b, v_lean_a*2 + v_bias_b))  \n",
    "# 2시간 학습 실제 성적: 81\n",
    "# 학습률 0.001: y = 2.2x + 80 2시간 예상 성적: 84\n",
    "# 학습률 0.01: y = 2.3x + 79 2시간 예상 성적: 83\n",
    "# 학습률 0.05: y = 2.3x + 79 2시간 예상 성적: 83\n",
    "# 학습률 0.1: y = 2.3x + 79 2시간 예상 성적: 83\n",
    "# 학습률 0.3: y = 2.9x + 79 2시간 예상 성적: 84\n",
    "# 학습률 0.6: y = 3.9x + 79 2시간 예상 성적: 86\n",
    "# 학습률 0.9: y = 4.7x + 79 2시간 예상 성적: 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR = '../../logs' # 폴더명만 지정하면 자동으로 생성됨.\n",
    " \n",
    "graph = tf.get_default_graph()\n",
    "with tf.summary.FileWriter(LOG_DIR) as writer:\n",
    "    writer.add_graph(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
